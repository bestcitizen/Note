---
layout: skill
title: Stream Data Processing - 실시간 정보 처리
date: 2024-12-26
---




## Stream Data Processing : 끊임없이 발생하는 정보를 실시간으로 처리하기

- **실시간 stream data을 정제하는 작업**은 stream 처리 방식의 ETL(Extract, Transform, Load) 과정 중 **Transform(변환) 단계**과 관련이 깊습니다.

- Stream Data Processing은 기업의 운영 방식과 경쟁력에 근본적인 변화를 가져올 수 있습니다.
    - 스트림 처리를 통해 데이터가 생성되자마자 분석 시스템에 데이터를 공급할 수 있습니다.
        - 기업은 거의 실시간으로 핵심적인 통찰력을 얻을 수 있습니다.
    - 실시간 의사 결정, 즉각적인 고객 대응, 실시간 위험 감지 등의 이점을 얻을 수 있습니다.


### Stream Processing이 Batch Processing보다 기술적으로 더 어려운 이유

- **스트리밍 환경은 실시간으로 결과를 반영**해야 하기 때문에, **지연(latency)이 허용되지 않습니다.**
    - 전통적인 batch ETL 방식에서는 데이터가 일정 기간 동안 축적된 후 처리되며, 통상적으로 몇시간 이상의 데이터 지연(latency)이 존재합니다.

1. **데이터 조인의 복잡성** : 실시간으로 들어오는 데이터를 조인하기 위해 **스트림 조인이라는 새로운 패러다임이 필요**합니다.
    - 기존 데이터와 조인해야 할 경우, 전통적인 데이터베이스 조인 방식으로는 처리가 불가능합니다.
    - 새로운 메모리 관리 방식, 새로운 상태 저장 방식이 필요합니다.

2. **자원 할당의 변화** : 스트리밍 환경에서는 지속적으로 높은 수준의 컴퓨팅 자원을 유지해야 하며, 이는 시스템 아키텍처와 비용 구조에 큰 영향을 미칩니다.
    - 배치 처리에서는 필요한 시점에 대량의 컴퓨팅 자원을 일시적으로 할당할 수 있었습니다.

3. **에러 처리의 중요성** : 실시간 스트리밍에서는 데이터 손실이나 처리 지연이 즉각적인 비즈니스 영향으로 이어질 수 있어, 훨씬 더 정교한 에러 처리와 복구 메커니즘이 필요합니다.
    - 배치 처리에서는 에러가 발생하면 전체 배치를 재실행할 수 있었습니다. 




---




## Stream Processing 기술 선택 가이드

- 개발자는 업무의 요건과 난이도에 따라서 실시간 지원을 위해 새로운 데이터 파이프라인을 설계하기도 하고, 빠른 처리를 위해 더 많은 리소스를 할당하기도 합니다.

- 이러한 데이터 처리를 위해 이미 수많은 도구들이 존재하며, 목적에 맞는 도구를 잘 선택하는 것이 중요합니다.
    - 업무의 편의성과 복잡성의 수준에 따라 사용하기 적합한 기술이 달라집니다.


### 1. 간단한 데이터 처리 도구

- 주로 메시지 조합과 기본적인 변환을 수행하는 데 적합한 도구들입니다.

#### Apache Nifi

- **웹 기반 UI**를 통해 직관적으로 데이터 파이프라인을 구성할 수 있습니다.
- 200개 이상의 프로세서를 제공하여 다양한 데이터 변환 작업이 가능하며, 특히 비개발자 운영팀이 관리하는 환경에 적합합니다.

#### Confluent KSQL

- SQL 기반의 스트리밍 처리를 지원하여 실시간 데이터 필터링, 집계, 조인 작업을 수행할 수 있습니다.
- Push Query를 통해 지속적으로 들어오는 메시지를 처리할 수 있어 실시간 대시보드 구축에 효과적입니다.


### 2. 기본적인 데이터 처리 도구

- 어느 정도의 데이터 프로세싱을 수행하는 방식이며, 러닝 커브는 존재하지만 상대적으로 손쉽게 데이터의 정제나 처리가 가능합니다.

#### Kafka Streams

- Java/Scala 기반으로 개발되며, 상태 기반 처리와 윈도우 연산을 지원합니다.
- 마이크로서비스 아키텍처와 잘 어울리며 중규모 데이터의 실시간 분석에 적합합니다.

#### AWS Kinesis

- AWS 환경에서 제공되는 관리형 서비스로, 자동 스케일링과 고가용성을 지원합니다.
- AWS 기반 인프라를 활용하는 조직에서 빠른 시스템 구축이 가능합니다.


### 3. 고급 데이터 처리 도구

- 고급 데이터 처리 도구는 복잡한 실시간 데이터 처리가 필요한 상황에서 사용됩니다.

- Flink나 Spark와 같은 고급 도구들은 사실상 모든 종류의 스트리밍 데이터 처리가 가능합니다.
    - 다른 도구들로는 처리하기 어려운 복잡한 연산이나 대용량 데이터 처리도 충분히 수행할 수 있기 때문에, 그보다 간단한 작업도 처리할 수 있습니다.
    - 그러나 러닝 커브가 높은 편이며, 개발자의 숙련도와 운영 경험이 중요하고, 초기 설정과 운영 관리에 상당한 공수가 필요합니다.
    - 따라서 단순한 데이터 처리만 필요한 경우에는 보다 가벼운 도구를 선택하는 것이 개발 생산성과 운영 효율성 측면에서 더 유리할 수 있습니다.

#### Apache Flink

- 정교한 이벤트 시간 처리와 초저지연 처리가 가능하며, Complex Event Processing(CEP)을 지원합니다.
- 금융 거래, 대규모 IoT 데이터 분석 등 고성능 실시간 처리가 필요한 환경에 적합합니다.

#### Apache Spark Streaming

- 배치와 스트리밍 처리를 통합할 수 있으며, 실시간 머신러닝 분석이 가능합니다.
- Scala, Java, Python, R 등 다양한 언어를 지원하여 개발 유연성이 높습니다.


### 4. 특수 목적 도구

- 특수 목적 도구들은 일반적인 스트림 처리 도구들과는 다른 접근 방식을 제공합니다.
    - 각각의 고유한 특성과 장점을 바탕으로, 특정 사용 사례나 환경에서 좋은 성능을 발휘합니다.

#### Apache Storm

- 밀리초 단위의 처리 지연시간을 보장하며, 자체 장애 복구 메커니즘을 제공합니다.
- 실시간 광고 플랫폼, 게임 서버의 실시간 이벤트 처리 등에 적합합니다.

#### Apache Beam

- Flink, Spark, Dataflow 등 여러 실행 엔진을 지원하는 통합 프로그래밍 모델을 제공합니다.
- 멀티 클라우드 환경에서 효과적으로 활용할 수 있습니다.

#### dbt

- SQL 기반의 데이터 변환을 지원하며, 버전 관리와 테스트 자동화 기능을 제공합니다.
- 데이터 웨어하우스 기반 분석과 데이터 품질 관리가 중요한 프로젝트에 적합합니다.




























### 간단한 데이터 처리 도구 : 메세지 조합/변환 수준의 데이터 프로세싱

#### Apache Nifi

- Apache Nifi는 WebUI를 통해 간단하게 메세지를 병합하거나 발췌하여 스트리밍으로 던질 수 있도록 되어 있습니다.

- 데이터 파이프라인 구축의 진입 장벽이 낮습니다.
    - 직관적인 웹 기반 UI를 제공합니다.
    - 드래그 앤 드롭 방식으로 구성이 가능합니다.

- 다양한 데이터 변환 작업이 가능합니다.
    - 200개 이상의 프로세서를 제공합니다.

- 데이터 수집과 라우팅이 주요한 시스템에 적합합니다.
    - 비개발자 운영팀이 직접 파이프라인을 관리할 때 효과적입니다.
    - 빠른 프로토타입 검증이 필요한 프로젝트에서 유용합니다.

#### Confluent KSQL

- 대규모 데이터 처리가 가능합니다.
    - SQL 기반의 스트리밍 처리를 지원합니다.
    - 기존 SQL 개발자들의 적응이 용이합니다.

- 실시간 데이터 처리 기능을 제공합니다.
    - 데이터 필터링, 집계, 조인 작업이 가능합니다.
    - 선언적 구현 방식을 지원합니다.

- Kafka 기반 실시간 분석 환경에 효과적입니다.
    - SQL 개발자가 많은 조직에서 생산성이 높습니다.
    - 실시간 대시보드 시스템 구축에 적합합니다.

- KSQL은 SQL 인터페이스를 제공하여 Push Query 형태로 Query Prompt를 종료하지 않고 지속적으로 들어오는 메세지에 대해 간략한 변환이나 Join 쿼리 결과를 메세지 큐에 전달하는 것이 가능합니다.
    - KSQL의 경우는 Push Query를 설정해두면 자동적으로 Trigger가 발생하는 것과 유사하게 메세지가 조합될 때마다 결과를 데이터 파이프에 전달하게 됩니다.
    - 가령, 세 곳에서 a,b,c 메세지 데이터가 들어오는데 각자 10초, 15초, 30초 주기로 발생한다고 가정하자.
    - 다른 복잡한 요건은 없고 1분 마다 데이터를 조합해서 만들어주면 된다고 하면, 60초 기준으로 큐를 설정하고 메세지를 조합하여 파이프라인에 전달하도록 구성할 수 있다.
    - 이 방법은 편의성이 높다는 장점이 있는 반면, 복잡한 데이터 프로세싱에 활용하기에는 적합하지 않다.


### 기본적인 데이터 처리 도구 : 일반적인 데이터 프로세싱

#### Kafka Streams

- 안정적인 스트리밍 처리가 가능합니다.
    - Java/Scala 기반 개발을 지원합니다.
    - Kafka 생태계와 완벽하게 통합됩니다.

- 다양한 스트리밍 작업을 구현할 수 있습니다.
    - 상태 기반 처리를 지원합니다.
    - 윈도우 연산이 가능합니다.

- 실시간 이벤트 기반 시스템에 적합합니다.
    - 마이크로서비스 아키텍처와 잘 어울립니다.
    - 중규모 데이터의 실시간 분석에 효과적입니다.

#### AWS Kinesis

- 운영 부담이 적습니다.
    - AWS 클라우드 환경에서 관리형 서비스를 제공합니다.
    - 자동 스케일링과 고가용성을 지원합니다.

- 통합 솔루션 구축이 용이합니다.
    - 다양한 AWS 서비스와 연동됩니다.

- 클라우드 네이티브 환경에 적합합니다.
    - AWS 기반 인프라 활용도가 높습니다.
    - 빠른 시스템 구축이 필요한 조직에 효과적입니다.


### 고급 데이터 처리 도구 : 복잡한 데이터 프로세싱

#### Apache Flink

- 미션 크리티컬한 환경에 적합합니다.
    - 정교한 이벤트 시간 처리 기능을 제공합니다.
    - 초저지연 처리가 가능합니다.
    - 상태 관리 기능을 제공합니다.

- 복잡한 이벤트 처리가 가능합니다.
    - CEP(Complex Event Processing) 구현을 지원합니다.

- 고성능 실시간 처리가 필요한 시스템에 적합합니다.
    - 금융 거래의 실시간 처리에 활용됩니다.
    - 대규모 IoT 데이터 분석에 효과적입니다.
    - 복잡한 이벤트 패턴 탐지에 강점이 있습니다.

#### Apache Spark Streaming

- 통합 데이터 처리 환경을 제공합니다.
    - 배치와 스트리밍 처리를 통합할 수 있습니다.
    - 실시간 머신러닝 분석이 가능합니다.

- 개발 유연성이 높습니다.
    - Scala, Java, Python, R 등 다양한 언어를 지원합니다.

- 대규모 데이터 처리 환경에 적합합니다.
    - 배치와 스트리밍 혼합 처리가 필요한 시스템에 효과적입니다.
    - 실시간 ML 모델 서빙 환경에서 강점을 보입니다.


### 특수 목적 도구 : 개성있는 데이터 프로세싱

#### Apache Storm

- 고신뢰성 실시간 처리가 가능합니다.
    - 밀리초 단위의 처리 지연시간을 보장합니다.
    - 자체 장애 복구 메커니즘을 제공합니다.

- 초고속 데이터 처리가 필요한 환경에 적합합니다.
    - 실시간 광고 플랫폼에 활용됩니다.
    - 게임 서버의 실시간 이벤트 처리에 효과적입니다.
    - 네트워크 모니터링 시스템 구축에 강점이 있습니다.

#### Apache Beam

- 멀티 엔진 실행이 가능합니다.
    - Flink, Spark, Dataflow 등 여러 실행 엔진을 지원합니다.
    - 통합 프로그래밍 모델을 제공합니다.

- 단일 API로 통합 관리가 가능합니다.
    - 배치와 스트리밍 처리를 함께 다룰 수 있습니다.

- 벤더 중립적인 환경 구축에 적합합니다.
    - 멀티 클라우드 환경에서 효과적입니다.
    - 실행 엔진 교체가 잦은 환경에서 유용합니다.

#### dbt

- 효율적인 데이터 파이프라인 구축이 가능합니다.
    - SQL 기반의 데이터 변환을 지원합니다.
    - 버전 관리와 테스트 자동화 기능을 제공합니다.
    - 증분 처리를 지원합니다.

- 분석 중심의 데이터 환경에 적합합니다.
    - 데이터 웨어하우스 기반 분석에 효과적입니다.
    - 데이터 품질 관리가 중요한 프로젝트에서 강점을 보입니다.




---




## Reference

- <http://cloudinsight.net/data/stream-data-processing-%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4>
